{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_LXpCpJ9mKsvSVnLUistMYXA7a76pgP-",
      "authorship_tag": "ABX9TyNDfNprYYJMT/1xdiiadpOd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenilGarala/fraud-detection-uniforms/blob/main/fraud_detection_uniforms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "!pip install tensorflow\n",
        "!pip install opencv-python==4.8.0.76\n",
        "!pip install matplotlib seaborn\n",
        "!pip install scikit-learn pandas\n",
        "!pip install tqdm requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P1Ns6jXtKWtK",
        "outputId": "ed067d11-c0ae-453a-e853-356afc101c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.25.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting opencv-python==4.8.0.76\n",
            "  Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from opencv-python==4.8.0.76) (1.26.4)\n",
            "Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "Successfully installed opencv-python-4.8.0.76\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn\n",
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lQ6puL2Ca12p",
        "outputId": "dc637400-43c9-4656-ea11-ccc486dfbec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from google.colab import drive, files\n",
        "import zipfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "0ICWf-C8bsmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/MyDrive')\n",
        "\n",
        "# Create proper directory structure\n",
        "base_dir = '/content/MyDrive/'\n",
        "os.makedirs(f'{base_dir}/uniform/train', exist_ok=True)\n",
        "os.makedirs(f'{base_dir}/uniform/test', exist_ok=True)\n",
        "\n",
        "print(\"Directory structure created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frORczmXn-zS",
        "outputId": "72230e8e-c7a5-4607-9443-a7f294000d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory structure created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self, data_path=\"Uniform\"):\n",
        "        self.data_path = data_path\n",
        "        self.image_size = (224, 224)  # EfficientNet input size\n",
        "\n",
        "    def load_and_preprocess_images(self):\n",
        "        \"\"\"Load and preprocess all images from train/test folders\"\"\"\n",
        "\n",
        "        train_images = []\n",
        "        test_images = []\n",
        "        train_labels = []\n",
        "        test_labels = []\n",
        "\n",
        "        # Process training data\n",
        "        train_path = os.path.join(self.data_path, \"train\")\n",
        "        if os.path.exists(train_path):\n",
        "            for filename in os.listdir(train_path):\n",
        "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(train_path, filename)\n",
        "                    img = self.preprocess_image(img_path)\n",
        "                    if img is not None:\n",
        "                        train_images.append(img)\n",
        "                        # Determine label based on filename or folder structure\n",
        "                        label = self.determine_label(filename)\n",
        "                        train_labels.append(label)\n",
        "\n",
        "        # Process test data\n",
        "        test_path = os.path.join(self.data_path, \"test\")\n",
        "        if os.path.exists(test_path):\n",
        "            for filename in os.listdir(test_path):\n",
        "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(test_path, filename)\n",
        "                    img = self.preprocess_image(img_path)\n",
        "                    if img is not None:\n",
        "                        test_images.append(img)\n",
        "                        label = self.determine_label(filename)\n",
        "                        test_labels.append(label)\n",
        "\n",
        "        return np.array(train_images), np.array(train_labels), np.array(test_images), np.array(test_labels)\n",
        "\n",
        "    def preprocess_image(self, img_path):\n",
        "        \"\"\"Preprocess single image\"\"\"\n",
        "        try:\n",
        "            # Read image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                return None\n",
        "\n",
        "            # Convert BGR to RGB\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Resize to target size\n",
        "            img = cv2.resize(img, self.image_size)\n",
        "\n",
        "            # Normalize pixel values\n",
        "            img = img.astype(np.float32) / 255.0\n",
        "\n",
        "            return img\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def determine_label(self, filename):\n",
        "        \"\"\"Determine label based on filename - you'll need to adapt this\"\"\"\n",
        "        # This is a simple example - modify based on your naming convention\n",
        "        filename_lower = filename.lower()\n",
        "\n",
        "        if any(keyword in filename_lower for keyword in ['police', 'cop', 'officer', 'uniform']):\n",
        "            return 1  # Uniform\n",
        "        else:\n",
        "            return 0  # Non-uniform\n",
        "\n",
        "    def create_organized_dataset(self):\n",
        "        \"\"\"Create properly organized dataset structure\"\"\"\n",
        "\n",
        "        # Create organized structure\n",
        "        organized_path = \"organized_dataset\"\n",
        "        os.makedirs(f\"{organized_path}/train/uniform\", exist_ok=True)\n",
        "        os.makedirs(f\"{organized_path}/train/non_uniform\", exist_ok=True)\n",
        "        os.makedirs(f\"{organized_path}/test/uniform\", exist_ok=True)\n",
        "        os.makedirs(f\"{organized_path}/test/non_uniform\", exist_ok=True)\n",
        "\n",
        "        print(\"Organized dataset structure created!\")\n",
        "        print(\"Please manually organize your images into:\")\n",
        "        print(\"- organized_dataset/train/uniform/ (for uniform images)\")\n",
        "        print(\"- organized_dataset/train/non_uniform/ (for civilian clothes)\")\n",
        "        print(\"- organized_dataset/test/uniform/ (for test uniform images)\")\n",
        "        print(\"- organized_dataset/test/non_uniform/ (for test civilian images)\")\n",
        "\n",
        "        return organized_path\n",
        "\n",
        "    def visualize_samples(self, images, labels, num_samples=8):\n",
        "        \"\"\"Visualize sample images\"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(min(num_samples, len(images))):\n",
        "            plt.subplot(2, 4, i+1)\n",
        "            plt.imshow(images[i])\n",
        "            label_text = \"Uniform\" if labels[i] == 1 else \"Non-uniform\"\n",
        "            plt.title(f\"Label: {label_text}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/sample_images.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# Usage example\n",
        "preprocessor = DataPreprocessor()\n",
        "\n",
        "# Create organized structure\n",
        "organized_path = preprocessor.create_organized_dataset()\n",
        "\n",
        "print(\"Data preprocessing setup completed!\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Organize your images in the created folder structure\")\n",
        "print(\"2. Run the image segmentation script\")\n",
        "print(\"3. Train the classification model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SdDTwWicD2S",
        "outputId": "d72020ec-18b6-4cdd-86a7-d3b4012336f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Organized dataset structure created!\n",
            "Please manually organize your images into:\n",
            "- organized_dataset/train/uniform/ (for uniform images)\n",
            "- organized_dataset/train/non_uniform/ (for civilian clothes)\n",
            "- organized_dataset/test/uniform/ (for test uniform images)\n",
            "- organized_dataset/test/non_uniform/ (for test civilian images)\n",
            "Data preprocessing setup completed!\n",
            "\n",
            "Next steps:\n",
            "1. Organize your images in the created folder structure\n",
            "2. Run the image segmentation script\n",
            "3. Train the classification model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class UniformSegmenter:\n",
        "    def __init__(self):\n",
        "        # Initialize MediaPipe solutions\n",
        "        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "        # Initialize models\n",
        "        self.selfie_segmentation = self.mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
        "        self.pose = self.mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
        "\n",
        "    def segment_person(self, image):\n",
        "        \"\"\"Segment person from background using MediaPipe\"\"\"\n",
        "\n",
        "        # Convert image to RGB if needed\n",
        "        if len(image.shape) == 3:\n",
        "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.shape[2] == 3 else image\n",
        "        else:\n",
        "            rgb_image = image\n",
        "\n",
        "        # Get segmentation mask\n",
        "        results = self.selfie_segmentation.process(rgb_image)\n",
        "\n",
        "        # Create binary mask\n",
        "        mask = results.segmentation_mask\n",
        "        mask_binary = (mask > 0.5).astype(np.uint8)\n",
        "\n",
        "        # Apply mask to original image\n",
        "        segmented_image = rgb_image * mask_binary[:, :, np.newaxis]\n",
        "\n",
        "        return segmented_image, mask_binary\n",
        "\n",
        "    def detect_pose_keypoints(self, image):\n",
        "        \"\"\"Detect pose keypoints to identify uniform regions\"\"\"\n",
        "\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image\n",
        "        results = self.pose.process(rgb_image)\n",
        "\n",
        "        keypoints = []\n",
        "        if results.pose_landmarks:\n",
        "            for landmark in results.pose_landmarks.landmark:\n",
        "                keypoints.append([landmark.x, landmark.y, landmark.z])\n",
        "\n",
        "        return np.array(keypoints), results\n",
        "\n",
        "    def extract_uniform_regions(self, image, keypoints):\n",
        "        \"\"\"Extract specific uniform regions based on pose keypoints\"\"\"\n",
        "\n",
        "        if len(keypoints) == 0:\n",
        "            return []\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        regions = []\n",
        "\n",
        "        # Define regions of interest for uniform detection\n",
        "        # Torso region (chest area)\n",
        "        if len(keypoints) >= 12:  # Ensure we have shoulder landmarks\n",
        "            left_shoulder = keypoints[11]  # Left shoulder\n",
        "            right_shoulder = keypoints[12]  # Right shoulder\n",
        "\n",
        "            # Calculate torso bounding box\n",
        "            chest_x1 = int(min(left_shoulder[0], right_shoulder[0]) * w) - 50\n",
        "            chest_x2 = int(max(left_shoulder[0], right_shoulder[0]) * w) + 50\n",
        "            chest_y1 = int(min(left_shoulder[1], right_shoulder[1]) * h)\n",
        "            chest_y2 = chest_y1 + 150  # Approximate chest height\n",
        "\n",
        "            # Ensure coordinates are within image bounds\n",
        "            chest_x1 = max(0, chest_x1)\n",
        "            chest_x2 = min(w, chest_x2)\n",
        "            chest_y1 = max(0, chest_y1)\n",
        "            chest_y2 = min(h, chest_y2)\n",
        "\n",
        "            if chest_x2 > chest_x1 and chest_y2 > chest_y1:\n",
        "                chest_region = image[chest_y1:chest_y2, chest_x1:chest_x2]\n",
        "                regions.append(('chest', chest_region, (chest_x1, chest_y1, chest_x2, chest_y2)))\n",
        "\n",
        "        # Head region (for caps/hats)\n",
        "        if len(keypoints) >= 1:\n",
        "            nose = keypoints[0]  # Nose landmark\n",
        "\n",
        "            head_x1 = int(nose[0] * w) - 80\n",
        "            head_x2 = int(nose[0] * w) + 80\n",
        "            head_y1 = int(nose[1] * h) - 120\n",
        "            head_y2 = int(nose[1] * h) - 20\n",
        "\n",
        "            head_x1 = max(0, head_x1)\n",
        "            head_x2 = min(w, head_x2)\n",
        "            head_y1 = max(0, head_y1)\n",
        "            head_y2 = min(h, head_y2)\n",
        "\n",
        "            if head_x2 > head_x1 and head_y2 > head_y1:\n",
        "                head_region = image[head_y1:head_y2, head_x1:head_x2]\n",
        "                regions.append(('head', head_region, (head_x1, head_y1, head_x2, head_y2)))\n",
        "\n",
        "        return regions\n",
        "\n",
        "    def process_image(self, image_path):\n",
        "        \"\"\"Complete processing pipeline for an image\"\"\"\n",
        "\n",
        "        # Read image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            return None, None, []\n",
        "\n",
        "        # Step 1: Segment person\n",
        "        segmented_image, mask = self.segment_person(image)\n",
        "\n",
        "        # Step 2: Detect pose keypoints\n",
        "        keypoints, pose_results = self.detect_pose_keypoints(image)\n",
        "\n",
        "        # Step 3: Extract uniform regions\n",
        "        regions = self.extract_uniform_regions(image, keypoints)\n",
        "\n",
        "        return segmented_image, mask, regions\n",
        "\n",
        "    def visualize_segmentation(self, original_image, segmented_image, mask, regions):\n",
        "        \"\"\"Visualize segmentation results\"\"\"\n",
        "\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "        # Original image\n",
        "        axes[0, 0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
        "        axes[0, 0].set_title('Original Image')\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # Segmented image\n",
        "        axes[0, 1].imshow(segmented_image)\n",
        "        axes[0, 1].set_title('Segmented Person')\n",
        "        axes[0, 1].axis('off')\n",
        "\n",
        "        # Segmentation mask\n",
        "        axes[0, 2].imshow(mask, cmap='gray')\n",
        "        axes[0, 2].set_title('Segmentation Mask')\n",
        "        axes[0, 2].axis('off')\n",
        "\n",
        "        # Show extracted regions\n",
        "        for i, (region_name, region_img, bbox) in enumerate(regions[:3]):\n",
        "            if i < 3:\n",
        "                if len(region_img.shape) == 3:\n",
        "                    axes[1, i].imshow(cv2.cvtColor(region_img, cv2.COLOR_BGR2RGB))\n",
        "                else:\n",
        "                    axes[1, i].imshow(region_img, cmap='gray')\n",
        "                axes[1, i].set_title(f'{region_name} Region')\n",
        "                axes[1, i].axis('off')\n",
        "\n",
        "        # Hide unused subplots\n",
        "        for i in range(len(regions), 3):\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/segmentation_results.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# Usage example\n",
        "def process_sample_images():\n",
        "    segmenter = UniformSegmenter()\n",
        "\n",
        "    # Process images from your dataset\n",
        "    data_path = \"Uniform/train\"\n",
        "    if os.path.exists(data_path):\n",
        "        sample_images = [f for f in os.listdir(data_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        for i, img_name in enumerate(sample_images[:3]):  # Process first 3 images as examples\n",
        "            img_path = os.path.join(data_path, img_name)\n",
        "            print(f\"Processing: {img_name}\")\n",
        "\n",
        "            original_image = cv2.imread(img_path)\n",
        "            segmented_image, mask, regions = segmenter.process_image(img_path)\n",
        "\n",
        "            if segmented_image is not None:\n",
        "                print(f\"Found {len(regions)} regions: {[r[0] for r in regions]}\")\n",
        "                segmenter.visualize_segmentation(original_image, segmented_image, mask, regions)\n",
        "            else:\n",
        "                print(f\"Failed to process {img_name}\")\n",
        "    else:\n",
        "        print(f\"Path {data_path} not found. Please upload your images first.\")\n",
        "\n",
        "# Initialize segmenter\n",
        "segmenter = UniformSegmenter()\n",
        "print(\"Image segmentation module ready!\")\n",
        "print(\"Run process_sample_images() to test segmentation on your data\")"
      ],
      "metadata": {
        "id": "V3ZBk_PJcV39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be67ae7-03ab-4482-afe3-0a515e38def1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image segmentation module ready!\n",
            "Run process_sample_images() to test segmentation on your data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "class UniformClassifier:\n",
        "    def __init__(self, input_shape=(224, 224, 3), num_classes=2):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"Create EfficientNet-Lite4 based model\"\"\"\n",
        "\n",
        "        # Load pre-trained EfficientNetB4 (closest to EfficientNet-Lite4)\n",
        "        base_model = EfficientNetB4(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=self.input_shape\n",
        "        )\n",
        "\n",
        "        # Freeze base model layers initially\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Add custom classification head\n",
        "        inputs = keras.Input(shape=self.input_shape)\n",
        "\n",
        "        # Preprocessing\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
        "\n",
        "        # Base model\n",
        "        x = base_model(x, training=False)\n",
        "\n",
        "        # Classification head\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        x = layers.Dense(256, activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.2)(x)\n",
        "        x = layers.Dense(128, activation='relu')(x)\n",
        "        x = layers.Dropout(0.2)(x)\n",
        "\n",
        "        # Output layer\n",
        "        outputs = layers.Dense(self.num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "        self.model = keras.Model(inputs, outputs)\n",
        "\n",
        "        # Compile model\n",
        "        self.model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def create_data_generators(self, train_dir, validation_split=0.2, batch_size=32):\n",
        "        \"\"\"Create data generators for training\"\"\"\n",
        "\n",
        "        # Data augmentation for training\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            validation_split=validation_split\n",
        "        )\n",
        "\n",
        "        # Generator for validation (no augmentation)\n",
        "        val_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            validation_split=validation_split\n",
        "        )\n",
        "\n",
        "        # Training generator\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=self.input_shape[:2],\n",
        "            batch_size=batch_size,\n",
        "            class_mode='sparse',\n",
        "            subset='training',\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        # Validation generator\n",
        "        val_generator = val_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=self.input_shape[:2],\n",
        "            batch_size=batch_size,\n",
        "            class_mode='sparse',\n",
        "            subset='validation',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        return train_generator, val_generator\n",
        "\n",
        "    def train_model(self, train_generator, val_generator, epochs=20):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "\n",
        "        # Callbacks\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=5,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=3,\n",
        "                min_lr=1e-7\n",
        "            ),\n",
        "            keras.callbacks.ModelCheckpoint(\n",
        "                'models/best_uniform_model.h5',\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                mode='max'\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train model\n",
        "        print(\"Starting training...\")\n",
        "        self.history = self.model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=val_generator.samples // val_generator.batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(\"Training completed!\")\n",
        "        return self.history\n",
        "\n",
        "    def fine_tune_model(self, train_generator, val_generator, epochs=10):\n",
        "        \"\"\"Fine-tune the model by unfreezing some layers\"\"\"\n",
        "\n",
        "        # Unfreeze the base model\n",
        "        self.model.layers[2].trainable = True  # EfficientNet base model\n",
        "\n",
        "        # Use lower learning rate for fine-tuning\n",
        "        self.model.compile(\n",
        "            optimizer=keras.optimizers.Adam(1e-5),\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        print(\"Fine-tuning model...\")\n",
        "        fine_tune_history = self.model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=val_generator.samples // val_generator.batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=[\n",
        "                keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "                keras.callbacks.ModelCheckpoint(\n",
        "                    'models/best_uniform_model_finetuned.h5',\n",
        "                    monitor='val_accuracy',\n",
        "                    save_best_only=True,\n",
        "                    mode='max'\n",
        "                )\n",
        "            ],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return fine_tune_history\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Plot training history\"\"\"\n",
        "        if self.history is None:\n",
        "            print(\"No training history available\")\n",
        "            return\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "        # Plot accuracy\n",
        "        ax1.plot(self.history.history['accuracy'], label='Training Accuracy')\n",
        "        ax1.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Plot loss\n",
        "        ax2.plot(self.history.history['loss'], label='Training Loss')\n",
        "        ax2.plot(self.history.history['val_loss'], label='Validation Loss')\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/training_history.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_model(self, test_generator):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "\n",
        "        # Get predictions\n",
        "        test_generator.reset()\n",
        "        predictions = self.model.predict(test_generator, verbose=1)\n",
        "        predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Get true labels\n",
        "        true_classes = test_generator.classes\n",
        "        class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "        # Print classification report\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        cm = confusion_matrix(true_classes, predicted_classes)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        return predictions, predicted_classes\n",
        "\n",
        "    def predict_single_image(self, image_path):\n",
        "        \"\"\"Predict single image\"\"\"\n",
        "\n",
        "        # Load and preprocess image\n",
        "        img = keras.utils.load_img(image_path, target_size=self.input_shape[:2])\n",
        "        img_array = keras.utils.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0)  # Create batch dimension\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = self.model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions[0])\n",
        "        confidence = predictions[0][predicted_class]\n",
        "\n",
        "        return predicted_class, confidence\n",
        "\n",
        "    def save_model(self, filepath='models/uniform_classifier.h5'):\n",
        "        \"\"\"Save the trained model\"\"\"\n",
        "        self.model.save(filepath)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath='models/uniform_classifier.h5'):\n",
        "        \"\"\"Load a trained model\"\"\"\n",
        "        self.model = keras.models.load_model(filepath)\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "# Usage example\n",
        "def train_uniform_classifier():\n",
        "    \"\"\"Complete training pipeline\"\"\"\n",
        "\n",
        "    # Initialize classifier\n",
        "    classifier = UniformClassifier()\n",
        "\n",
        "    # Create model\n",
        "    model = classifier.create_model()\n",
        "    print(\"Model created!\")\n",
        "    print(f\"Total parameters: {model.count_params():,}\")\n",
        "\n",
        "    # Check if organized dataset exists\n",
        "    train_dir = \"organized_dataset/train\"\n",
        "    if not os.path.exists(train_dir):\n",
        "        print(\"Organized dataset not found!\")\n",
        "        print(\"Please create the directory structure:\")\n",
        "        print(\"organized_dataset/\")\n",
        "        print(\"├── train/\")\n",
        "        print(\"│   ├── uniform/\")\n",
        "        print(\"│   └── non_uniform/\")\n",
        "        print(\"└── test/\")\n",
        "        print(\"    ├── uniform/\")\n",
        "        print(\"    └── non_uniform/\")\n",
        "        return None\n",
        "\n",
        "    # Create data generators\n",
        "    train_gen, val_gen = classifier.create_data_generators(train_dir)\n",
        "\n",
        "    print(f\"Training samples: {train_gen.samples}\")\n",
        "    print(f\"Validation samples: {val_gen.samples}\")\n",
        "    print(f\"Classes: {train_gen.class_indices}\")\n",
        "\n",
        "    # Train model\n",
        "    history = classifier.train_model(train_gen, val_gen, epochs=20)\n",
        "\n",
        "    # Plot training history\n",
        "    classifier.plot_training_history()\n",
        "\n",
        "    # Fine-tune model\n",
        "    fine_tune_history = classifier.fine_tune_model(train_gen, val_gen, epochs=10)\n",
        "\n",
        "    # Save model\n",
        "    classifier.save_model()\n",
        "\n",
        "    return classifier\n",
        "\n",
        "# Initialize\n",
        "print(\"Uniform classifier module ready!\")\n",
        "print(\"Make sure to organize your data first, then run train_uniform_classifier()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ah1ugYUod7p",
        "outputId": "e2d26a1c-d84e-4b10-e576-2f97a76cd7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uniform classifier module ready!\n",
            "Make sure to organize your data first, then run train_uniform_classifier()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class UniformFraudDetector:\n",
        "    def __init__(self, model_path='models/uniform_classifier.h5'):\n",
        "        \"\"\"Initialize the complete fraud detection system\"\"\"\n",
        "\n",
        "        # Initialize components\n",
        "        from image_segmentation import UniformSegmenter\n",
        "        from classification_model import UniformClassifier\n",
        "\n",
        "        self.segmenter = UniformSegmenter()\n",
        "        self.classifier = UniformClassifier()\n",
        "\n",
        "        # Load trained model\n",
        "        if os.path.exists(model_path):\n",
        "            self.classifier.load_model(model_path)\n",
        "            print(\"Trained model loaded successfully!\")\n",
        "        else:\n",
        "            print(f\"Model not found at {model_path}. Please train the model first.\")\n",
        "\n",
        "    def detect_fraud(self, image_path, confidence_threshold=0.7):\n",
        "        \"\"\"Complete fraud detection pipeline\"\"\"\n",
        "\n",
        "        results = {\n",
        "            'image_path': image_path,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'fraud_detected': False,\n",
        "            'confidence_scores': {},\n",
        "            'regions_analyzed': [],\n",
        "            'overall_confidence': 0.0,\n",
        "            'verdict': 'GENUINE'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Step 1: Load and preprocess image\n",
        "            original_image = cv2.imread(image_path)\n",
        "            if original_image is None:\n",
        "                results['error'] = \"Could not load image\"\n",
        "                return results\n",
        "\n",
        "            # Step 2: Segment person and extract regions\n",
        "            segmented_image, mask, regions = self.segmenter.process_image(image_path)\n",
        "\n",
        "            if not regions:\n",
        "                results['error'] = \"No person detected in image\"\n",
        "                return results\n",
        "\n",
        "            # Step 3: Classify each extracted region\n",
        "            region_predictions = []\n",
        "            total_confidence = 0\n",
        "\n",
        "            for region_name, region_img, bbox in regions:\n",
        "                # Save region as temporary file for classification\n",
        "                temp_path = f\"temp_{region_name}.jpg\"\n",
        "                cv2.imwrite(temp_path, region_img)\n",
        "\n",
        "                # Classify region\n",
        "                try:\n",
        "                    predicted_class, confidence = self.classifier.predict_single_image(temp_path)\n",
        "\n",
        "                    region_result = {\n",
        "                        'region': region_name,\n",
        "                        'predicted_class': int(predicted_class),\n",
        "                        'confidence': float(confidence),\n",
        "                        'is_uniform': predicted_class == 1,\n",
        "                        'bbox': bbox\n",
        "                    }\n",
        "\n",
        "                    region_predictions.append(region_result)\n",
        "                    results['regions_analyzed'].append(region_result)\n",
        "                    results['confidence_scores'][region_name] = float(confidence)\n",
        "\n",
        "                    total_confidence += confidence\n",
        "\n",
        "                    # Clean up temp file\n",
        "                    if os.path.exists(temp_path):\n",
        "                        os.remove(temp_path)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error classifying {region_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Step 4: Make overall decision\n",
        "            if region_predictions:\n",
        "                # Calculate overall confidence\n",
        "                results['overall_confidence'] = total_confidence / len(region_predictions)\n",
        "\n",
        "                # Check if any region is classified as uniform with high confidence\n",
        "                uniform_detections = [r for r in region_predictions if r['is_uniform'] and r['confidence'] > confidence_threshold]\n",
        "\n",
        "                if uniform_detections:\n",
        "                    results['fraud_detected'] = True\n",
        "                    results['verdict'] = 'POTENTIAL FRAUD - UNIFORM DETECTED'\n",
        "\n",
        "                    # Find the most confident uniform detection\n",
        "                    best_detection = max(uniform_detections, key=lambda x: x['confidence'])\n",
        "                    results['primary_detection'] = best_detection\n",
        "                else:\n",
        "                    results['verdict'] = 'GENUINE - NO UNIFORM DETECTED'\n",
        "\n",
        "        except Exception as e:\n",
        "            results['error'] = str(e)\n",
        "            print(f\"Error in fraud detection: {e}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def visualize_detection_results(self, image_path, results):\n",
        "        \"\"\"Visualize detection results\"\"\"\n",
        "\n",
        "        # Load original image\n",
        "        original_image = cv2.imread(image_path)\n",
        "        if original_image is None:\n",
        "            return\n",
        "\n",
        "        # Convert to RGB for matplotlib\n",
        "        display_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create figure\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
        "\n",
        "        # Show original image\n",
        "        axes[0].imshow(display_image)\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Show image with detection boxes\n",
        "        result_image = display_image.copy()\n",
        "\n",
        "        if 'regions_analyzed' in results:\n",
        "            for region in results['regions_analyzed']:\n",
        "                bbox = region['bbox']\n",
        "                x1, y1, x2, y2 = bbox\n",
        "\n",
        "                # Choose color based on classification\n",
        "                color = (255, 0, 0) if region['is_uniform'] else (0, 255, 0)  # Red for uniform, Green for non-uniform\n",
        "                thickness = 3 if region['is_uniform'] else 2\n",
        "\n",
        "                # Draw rectangle\n",
        "                cv2.rectangle(result_image, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "                # Add label\n",
        "                label = f\"{region['region']}: {'UNIFORM' if region['is_uniform'] else 'CIVILIAN'} ({region['confidence']:.2f})\"\n",
        "                cv2.putText(result_image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "        axes[1].imshow(result_image)\n",
        "        axes[1].set_title(f\"Detection Results - {results['verdict']}\")\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        # Add results text\n",
        "        results_text = f\"Overall Confidence: {results['overall_confidence']:.2f}\\n\"\n",
        "        results_text += f\"Fraud Detected: {results['fraud_detected']}\\n\"\n",
        "        results_text += f\"Regions Analyzed: {len(results.get('regions_analyzed', []))}\"\n",
        "\n",
        "        fig.suptitle(results_text, fontsize=12)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save results\n",
        "        output_path = f\"results/detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    def batch_process_images(self, image_folder, output_file='results/batch_results.json'):\n",
        "        \"\"\"Process multiple images and save results\"\"\"\n",
        "\n",
        "        all_results = []\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "        # Get all image files\n",
        "        image_files = [f for f in os.listdir(image_folder)\n",
        "                      if any(f.lower().endswith(ext) for ext in image_extensions)]\n",
        "\n",
        "        print(f\"Processing {len(image_files)} images...\")\n",
        "\n",
        "        for i, filename in enumerate(image_files):\n",
        "            print(f\"Processing {i+1}/{len(image_files)}: {filename}\")\n",
        "\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            results = self.detect_fraud(image_path)\n",
        "            all_results.append(results)\n",
        "\n",
        "            # Visualize results for first few images\n",
        "            if i < 5:  # Show first 5 results\n",
        "                self.visualize_detection_results(image_path, results)\n",
        "\n",
        "        # Save all results\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(all_results, f, indent=2)\n",
        "\n",
        "        # Generate summary statistics\n",
        "        self.generate_batch_summary(all_results)\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def generate_batch_summary(self, results):\n",
        "        \"\"\"Generate summary statistics from batch processing\"\"\"\n",
        "\n",
        "        if not results:\n",
        "            return\n",
        "\n",
        "        total_images = len(results)\n",
        "        fraud_detected = sum(1 for r in results if r.get('fraud_detected', False))\n",
        "        successful_processing = sum(1 for r in results if 'error' not in r)\n",
        "\n",
        "        # Calculate average confidence\n",
        "        confidences = [r['overall_confidence'] for r in results if r.get('overall_confidence', 0) > 0]\n",
        "        avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"BATCH PROCESSING SUMMARY\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Total Images Processed: {total_images}\")\n",
        "        print(f\"Successfully Processed: {successful_processing}\")\n",
        "        print(f\"Potential Fraud Detected: {fraud_detected} ({fraud_detected/total_images*100:.1f}%)\")\n",
        "        print(f\"Average Confidence Score: {avg_confidence:.2f}\")\n",
        "        print(f\"Processing Success Rate: {successful_processing/total_images*100:.1f}%\")\n",
        "\n",
        "        # Region analysis summary\n",
        "        region_counts = {}\n",
        "        for result in results:\n",
        "            for region in result.get('regions_analyzed', []):\n",
        "                region_name = region['region']\n",
        "                region_counts[region_name] = region_counts.get(region_name, 0) + 1\n",
        "\n",
        "        if region_counts:\n",
        "            print(f\"\\nRegions Analyzed:\")\n",
        "            for region, count in region_counts.items():\n",
        "                print(f\"  {region}: {count} detections\")\n",
        "\n",
        "        print(\"=\"*50)\n",
        "\n",
        "# Testing and demonstration functions\n",
        "def test_single_image(image_path):\n",
        "    \"\"\"Test fraud detection on a single image\"\"\"\n",
        "\n",
        "    detector = UniformFraudDetector()\n",
        "    results = detector.detect_fraud(image_path)\n",
        "    detector.visualize_detection_results(image_path, results)\n",
        "\n",
        "    print(\"\\nDetection Results:\")\n",
        "    print(f\"Verdict: {results['verdict']}\")\n",
        "    print(f\"Fraud Detected: {results['fraud_detected']}\")\n",
        "    print(f\"Overall Confidence: {results['overall_confidence']:.2f}\")\n",
        "\n",
        "    if results.get('regions_analyzed'):\n",
        "        print(\"\\nRegion Analysis:\")\n",
        "        for region in results['regions_analyzed']:\n",
        "            print(f\"  {region['region']}: {'UNIFORM' if region['is_uniform'] else 'CIVILIAN'} \"\n",
        "                  f\"(confidence: {region['confidence']:.2f})\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def run_demo():\n",
        "    \"\"\"Run a complete demonstration\"\"\"\n",
        "\n",
        "    print(\"UNIFORM FRAUD DETECTION SYSTEM DEMO\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check if model exists\n",
        "    if not os.path.exists('models/uniform_classifier.h5'):\n",
        "        print(\"❌ Trained model not found!\")\n",
        "        print(\"Please train the model first using the classification_model.py script\")\n",
        "        return\n",
        "\n",
        "    # Check if test images exist\n",
        "    test_folder = \"Uniform/test\"\n",
        "    if not os.path.exists(test_folder):\n",
        "        print(\"❌ Test folder not found!\")\n",
        "        print(\"Please upload test images to Uniform/test/ folder\")\n",
        "        return\n",
        "\n",
        "    # Initialize detector\n",
        "    try:\n",
        "        detector = UniformFraudDetector()\n",
        "        print(\"✅ Fraud detector initialized successfully!\")\n",
        "\n",
        "        # Process test images\n",
        "        print(\"\\nProcessing test images...\")\n",
        "        results = detector.batch_process_images(test_folder)\n",
        "\n",
        "        print(f\"✅ Processed {len(results)} images successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during demo: {e}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Complete Uniform Fraud Detection Pipeline Ready!\")\n",
        "    print(\"\\nAvailable functions:\")\n",
        "    print(\"- test_single_image(image_path): Test on single image\")\n",
        "    print(\"- run_demo(): Run complete demonstration\")\n",
        "    print(\"- UniformFraudDetector(): Initialize detector class\")\n",
        "\n",
        "    # Uncomment to run demo automatically\n",
        "    # run_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhAGXyYTo4LD",
        "outputId": "5eddadbc-002a-4446-d536-17e8a6a22076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete Uniform Fraud Detection Pipeline Ready!\n",
            "\n",
            "Available functions:\n",
            "- test_single_image(image_path): Test on single image\n",
            "- run_demo(): Run complete demonstration\n",
            "- UniformFraudDetector(): Initialize detector class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# from complete_pipeline import UniformFraudDetector # Remove this line\n",
        "from __main__ import UniformFraudDetector # Import from the current notebook environment\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, model_path='models/uniform_classifier.h5'):\n",
        "        self.detector = UniformFraudDetector(model_path)\n",
        "        self.test_results = []\n",
        "\n",
        "    def evaluate_test_dataset(self, test_folder, ground_truth_file=None):\n",
        "        \"\"\"Evaluate model on test dataset with known labels\"\"\"\n",
        "\n",
        "        # Create ground truth mapping if not provided\n",
        "        if ground_truth_file is None:\n",
        "            ground_truth = self.create_ground_truth_mapping(test_folder)\n",
        "        else:\n",
        "            with open(ground_truth_file, 'r') as f:\n",
        "                ground_truth = json.load(f)\n",
        "\n",
        "        print(f\"Evaluating on {len(ground_truth)} test images...\")\n",
        "\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "        detailed_results = []\n",
        "\n",
        "        for filename, true_label in ground_truth.items():\n",
        "            image_path = os.path.join(test_folder, filename)\n",
        "\n",
        "            if not os.path.exists(image_path):\n",
        "                continue\n",
        "\n",
        "            print(f\"Testing: {filename}\")\n",
        "\n",
        "            # Run fraud detection\n",
        "            result = self.detector.detect_fraud(image_path)\n",
        "\n",
        "            # Extract prediction\n",
        "            predicted_label = 1 if result['fraud_detected'] else 0\n",
        "\n",
        "            predictions.append(predicted_label)\n",
        "            true_labels.append(true_label)\n",
        "\n",
        "            # Store detailed results\n",
        "            detailed_results.append({\n",
        "                'filename': filename,\n",
        "                'true_label': true_label,\n",
        "                'predicted_label': predicted_label,\n",
        "                'confidence': result['overall_confidence'],\n",
        "                'verdict': result['verdict'],\n",
        "                'regions_detected': len(result.get('regions_analyzed', []))\n",
        "            })\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(true_labels, predictions)\n",
        "        precision = precision_score(true_labels, predictions)\n",
        "        recall = recall_score(true_labels, predictions)\n",
        "        f1 = f1_score(true_labels, predictions)\n",
        "\n",
        "        metrics = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'total_samples': len(true_labels),\n",
        "            'true_positives': sum(1 for t, p in zip(true_labels, predictions) if t == 1 and p == 1),\n",
        "            'false_positives': sum(1 for t, p in zip(true_labels, predictions) if t == 0 and p == 1),\n",
        "            'true_negatives': sum(1 for t, p in zip(true_labels, predictions) if t == 0 and p == 0),\n",
        "            'false_negatives': sum(1 for t, p in zip(true_labels, predictions) if t == 1 and p == 0)\n",
        "        }\n",
        "\n",
        "        # Save detailed results\n",
        "        self.save_evaluation_results(detailed_results, metrics)\n",
        "\n",
        "        # Create visualizations\n",
        "        self.create_evaluation_plots(true_labels, predictions, detailed_results)\n",
        "\n",
        "        return metrics, detailed_results\n",
        "\n",
        "    def create_ground_truth_mapping(self, test_folder):\n",
        "        \"\"\"Create ground truth mapping based on folder structure or filename patterns\"\"\"\n",
        "\n",
        "        ground_truth = {}\n",
        "\n",
        "        # Check if organized structure exists\n",
        "        uniform_folder = os.path.join(test_folder, 'uniform')\n",
        "        non_uniform_folder = os.path.join(test_folder, 'non_uniform')\n",
        "\n",
        "        if os.path.exists(uniform_folder) and os.path.exists(non_uniform_folder):\n",
        "            # Organized structure\n",
        "            for filename in os.listdir(uniform_folder):\n",
        "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    ground_truth[filename] = 1  # Uniform\n",
        "\n",
        "            for filename in os.listdir(non_uniform_folder):\n",
        "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    ground_truth[filename] = 0  # Non-uniform\n",
        "        else:\n",
        "            # Fallback: use filename patterns\n",
        "            for filename in os.listdir(test_folder):\n",
        "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    # Simple pattern matching - you may need to adjust this\n",
        "                    if any(keyword in filename.lower() for keyword in ['police', 'officer', 'uniform', 'army', 'military']):\n",
        "                        ground_truth[filename] = 1\n",
        "                    else:\n",
        "                        ground_truth[filename] = 0\n",
        "\n",
        "        print(f\"Created ground truth mapping for {len(ground_truth)} images\")\n",
        "        print(f\"Uniform samples: {sum(ground_truth.values())}\")\n",
        "        print(f\"Non-uniform samples: {len(ground_truth) - sum(ground_truth.values())}\")\n",
        "\n",
        "        return ground_truth\n",
        "\n",
        "    def save_evaluation_results(self, detailed_results, metrics):\n",
        "        \"\"\"Save evaluation results to files\"\"\"\n",
        "\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        # Save detailed results\n",
        "        with open(f'results/detailed_results_{timestamp}.json', 'w') as f:\n",
        "            json.dump(detailed_results, f, indent=2)\n",
        "\n",
        "        # Save metrics\n",
        "        with open(f'results/metrics_{timestamp}.json', 'w') as f:\n",
        "            json.dump(metrics, f, indent=2)\n",
        "\n",
        "        # Create CSV for easy analysis\n",
        "        df = pd.DataFrame(detailed_results)\n",
        "        df.to_csv(f'results/results_{timestamp}.csv', index=False)\n",
        "\n",
        "        print(f\"Results saved with timestamp: {timestamp}\")\n",
        "\n",
        "    def create_evaluation_plots(self, true_labels, predictions, detailed_results):\n",
        "        \"\"\"Create evaluation visualizations\"\"\"\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "        # Confusion Matrix\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['Non-Uniform', 'Uniform'],\n",
        "                   yticklabels=['Non-Uniform', 'Uniform'], ax=axes[0,0])\n",
        "        axes[0,0].set_title('Confusion Matrix')\n",
        "        axes[0,0].set_xlabel('Predicted')\n",
        "        axes[0,0].set_ylabel('Actual')\n",
        "\n",
        "        # Confidence Distribution\n",
        "        df = pd.DataFrame(detailed_results)\n",
        "        df_correct = df[df['true_label'] == df['predicted_label']]\n",
        "        df_incorrect = df[df['true_label'] != df['predicted_label']]\n",
        "\n",
        "        axes[0,1].hist(df_correct['confidence'], alpha=0.7, label='Correct Predictions', bins=20)\n",
        "        axes[0,1].hist(df_incorrect['confidence'], alpha=0.7, label='Incorrect Predictions', bins=20)\n",
        "        axes[0,1].set_title('Confidence Score Distribution')\n",
        "        axes[0,1].set_xlabel('Confidence Score')\n",
        "        axes[0,1].set_ylabel('Frequency')\n",
        "        axes[0,1].legend()\n",
        "\n",
        "        # Accuracy by Confidence Threshold\n",
        "        thresholds = np.arange(0.1, 1.0, 0.05)\n",
        "        accuracies = []\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            # Filter predictions by confidence threshold\n",
        "            high_conf_mask = df['confidence'] >= threshold\n",
        "            if high_conf_mask.sum() > 0:\n",
        "                filtered_true = df[high_conf_mask]['true_label']\n",
        "                filtered_pred = df[high_conf_mask]['predicted_label']\n",
        "                acc = accuracy_score(filtered_true, filtered_pred)\n",
        "                accuracies.append(acc)\n",
        "            else:\n",
        "                accuracies.append(0)\n",
        "\n",
        "        axes[1,0].plot(thresholds, accuracies, marker='o')\n",
        "        axes[1,0].set_title('Accuracy vs Confidence Threshold')\n",
        "        axes[1,0].set_xlabel('Minimum Confidence Threshold')\n",
        "        axes[1,0].set_ylabel('Accuracy')\n",
        "        axes[1,0].grid(True)\n",
        "\n",
        "        # Sample Coverage by Confidence Threshold\n",
        "        coverage = []\n",
        "        for threshold in thresholds:\n",
        "            coverage.append((df['confidence'] >= threshold).mean())\n",
        "\n",
        "        axes[1,1].plot(thresholds, coverage, marker='s', color='orange')\n",
        "        axes[1,1].set_title('Sample Coverage vs Confidence Threshold')\n",
        "        axes[1,1].set_xlabel('Minimum Confidence Threshold')\n",
        "        axes[1,1].set_ylabel('Fraction of Samples Retained')\n",
        "        axes[1,1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/evaluation_plots.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def performance_report(self, metrics):\n",
        "        \"\"\"Print detailed performance report\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"MODEL PERFORMANCE REPORT\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Dataset Size: {metrics['total_samples']} images\")\n",
        "        print(f\"Accuracy: {metrics['accuracy']:.3f} ({metrics['accuracy']*100:.1f}%)\")\n",
        "        print(f\"Precision: {metrics['precision']:.3f}\")\n",
        "        print(f\"Recall: {metrics['recall']:.3f}\")\n",
        "        print(f\"F1-Score: {metrics['f1_score']:.3f}\")\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(f\"True Positives (Correctly detected fraud): {metrics['true_positives']}\")\n",
        "        print(f\"True Negatives (Correctly detected genuine): {metrics['true_negatives']}\")\n",
        "        print(f\"False Positives (Incorrectly flagged as fraud): {metrics['false_positives']}\")\n",
        "        print(f\"False Negatives (Missed fraud cases): {metrics['false_negatives']}\")\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        specificity = metrics['true_negatives'] / (metrics['true_negatives'] + metrics['false_positives'])\n",
        "        print(f\"\\nSpecificity (True Negative Rate): {specificity:.3f}\")\n",
        "\n",
        "        if metrics['true_positives'] + metrics['false_negatives'] > 0:\n",
        "            sensitivity = metrics['true_positives'] / (metrics['true_positives'] + metrics['false_negatives'])\n",
        "            print(f\"Sensitivity (True Positive Rate): {sensitivity:.3f}\")\n",
        "\n",
        "        print(\"=\"*60)\n",
        "\n",
        "def run_comprehensive_evaluation():\n",
        "    \"\"\"Run comprehensive evaluation of the fraud detection system\"\"\"\n",
        "\n",
        "    print(\"Starting Comprehensive Model Evaluation...\")\n",
        "\n",
        "    # Check if model exists\n",
        "    if not os.path.exists('models/uniform_classifier.h5'):\n",
        "        print(\"❌ Trained model not found!\")\n",
        "        print(\"Please train the model first.\")\n",
        "        return\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = ModelEvaluator()\n",
        "\n",
        "    # Check test data structure\n",
        "    test_folder = \"organized_dataset/test\"\n",
        "    if not os.path.exists(test_folder):\n",
        "        test_folder = \"Uniform/test\"\n",
        "        if not os.path.exists(test_folder):\n",
        "            print(\"❌ Test folder not found!\")\n",
        "            print(\"Please ensure test data is available in 'organized_dataset/test' or 'Uniform/test'\")\n",
        "            return\n",
        "\n",
        "    try:\n",
        "        # Run evaluation\n",
        "        print(f\"Using test folder: {test_folder}\")\n",
        "        metrics, detailed_results = evaluator.evaluate_test_dataset(test_folder)\n",
        "\n",
        "        # Print performance report\n",
        "        evaluator.performance_report(metrics)\n",
        "\n",
        "        # Analyze failure cases\n",
        "        df = pd.DataFrame(detailed_results)\n",
        "        failures = df[df['true_label'] != df['predicted_label']]\n",
        "\n",
        "        if len(failures) > 0:\n",
        "            print(f\"\\nFAILURE ANALYSIS:\")\n",
        "            print(f\"Total failures: {len(failures)}\")\n",
        "            print(\"Failed cases:\")\n",
        "            for _, row in failures.head(10).iterrows():  # Show first 10 failures\n",
        "                print(f\"  {row['filename']}: True={row['true_label']}, \"\n",
        "                      f\"Pred={row['predicted_label']}, Conf={row['confidence']:.2f}\")\n",
        "\n",
        "        print(\"\\n✅ Evaluation completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during evaluation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Quick test functions\n",
        "def quick_test(image_path):\n",
        "    \"\"\"Quick test on a single image\"\"\"\n",
        "\n",
        "    detector = UniformFraudDetector()\n",
        "    result = detector.detect_fraud(image_path)\n",
        "    detector.visualize_detection_results(image_path, result)\n",
        "\n",
        "    print(f\"\\nQuick Test Results for: {os.path.basename(image_path)}\")\n",
        "    print(f\"Verdict: {result['verdict']}\")\n",
        "    print(f\"Confidence: {result['overall_confidence']:.2f}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Model Evaluation and Testing Module Ready!\")\n",
        "    print(\"\\nAvailable functions:\")\n",
        "    print(\"- run_comprehensive_evaluation(): Full model evaluation\")\n",
        "    print(\"- quick_test(image_path): Quick test on single image\")\n",
        "\n",
        "    # Uncomment to run evaluation automatically\n",
        "    # run_comprehensive_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woh7U2txpHuZ",
        "outputId": "bbd4fde8-19fb-4aa4-8c6d-9e51c5a913e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation and Testing Module Ready!\n",
            "\n",
            "Available functions:\n",
            "- run_comprehensive_evaluation(): Full model evaluation\n",
            "- quick_test(image_path): Quick test on single image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_project_structure():\n",
        "    \"\"\"Create project directory structure\"\"\"\n",
        "\n",
        "    directories = [\n",
        "        'models',\n",
        "        'results',\n",
        "        'data',\n",
        "        'organized_dataset/train/uniform',\n",
        "        'organized_dataset/train/non_uniform',\n",
        "        'organized_dataset/test/uniform',\n",
        "        'organized_dataset/test/non_uniform',\n",
        "        'temp'\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    print(\"✅ Project structure created!\")\n",
        "\n",
        "def organize_existing_data():\n",
        "    \"\"\"Help organize existing data into proper structure\"\"\"\n",
        "\n",
        "    # Check if original Uniform folder exists\n",
        "    if os.path.exists('Uniform'):\n",
        "        print(\"Found existing 'Uniform' folder with data.\")\n",
        "        print(\"Please manually organize images into:\")\n",
        "        print(\"📁 organized_dataset/\")\n",
        "        print(\"  ├── 📁 train/\")\n",
        "        print(\"  │   ├── 📁 uniform/ (put uniform images here)\")\n",
        "        print(\"  │   └── 📁 non_uniform/ (put civilian clothes images here)\")\n",
        "        print(\"  └── 📁 test/\")\n",
        "        print(\"      ├── 📁 uniform/ (put test uniform images here)\")\n",
        "        print(\"      └── 📁 non_uniform/ (put test civilian images here)\")\n",
        "        print()\n",
        "        print(\"💡 Tip: Aim for 200-300 images per category for best results\")\n",
        "\n",
        "        # Create example organization script\n",
        "        create_organization_helper()\n",
        "    else:\n",
        "        print(\"No existing 'Uniform' folder found.\")\n",
        "        print(\"Please upload your images and organize them as described above.\")\n",
        "\n",
        "def create_organization_helper():\n",
        "    \"\"\"Create a helper script to organize data\"\"\"\n",
        "\n",
        "    helper_code = '''\n",
        "# Data Organization Helper Script\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def organize_images():\n",
        "    \"\"\"Helper to organize images - modify as needed\"\"\"\n",
        "\n",
        "    source_train = \"Uniform/train\"\n",
        "    source_test = \"Uniform/test\"\n",
        "\n",
        "    if os.path.exists(source_train):\n",
        "        print(f\"Found {len(os.listdir(source_train))} images in train folder\")\n",
        "\n",
        "        # You'll need to manually sort these based on content\n",
        "        for filename in os.listdir(source_train):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                print(f\"Process: {filename}\")\n",
        "                # Manually move to appropriate folder:\n",
        "                # shutil.copy(os.path.join(source_train, filename),\n",
        "                #            \"organized_dataset/train/uniform/\")  # or non_uniform\n",
        "\n",
        "    print(\"Manual organization required - examine each image and sort accordingly\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    organize_images()\n",
        "'''\n",
        "\n",
        "    with open('organize_data.py', 'w') as f:\n",
        "        f.write(helper_code)\n",
        "\n",
        "    print(\"Created 'organize_data.py' helper script\")\n",
        "\n",
        "def check_data_ready():\n",
        "    \"\"\"Check if data is properly organized and ready\"\"\"\n",
        "\n",
        "    train_uniform = \"organized_dataset/train/uniform\"\n",
        "    train_non_uniform = \"organized_dataset/train/non_uniform\"\n",
        "    test_uniform = \"organized_dataset/test/uniform\"\n",
        "    test_non_uniform = \"organized_dataset/test/non_uniform\"\n",
        "\n",
        "    counts = {}\n",
        "    for folder_name, folder_path in [\n",
        "        (\"Train Uniform\", train_uniform),\n",
        "        (\"Train Non-Uniform\", train_non_uniform),\n",
        "        (\"Test Uniform\", test_uniform),\n",
        "        (\"Test Non-Uniform\", test_non_uniform)\n",
        "    ]:\n",
        "        if os.path.exists(folder_path):\n",
        "            count = len([f for f in os.listdir(folder_path)\n",
        "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            counts[folder_name] = count\n",
        "        else:\n",
        "            counts[folder_name] = 0\n",
        "\n",
        "    print(\"📊 Data Organization Status:\")\n",
        "    for category, count in counts.items():\n",
        "        status = \"✅\" if count > 50 else \"⚠️\" if count > 10 else \"❌\"\n",
        "        print(f\"{status} {category}: {count} images\")\n",
        "\n",
        "    total_images = sum(counts.values())\n",
        "    min_recommended = 800  # 200 per category\n",
        "\n",
        "    if total_images >= min_recommended:\n",
        "        print(f\"\\n✅ Dataset ready! Total: {total_images} images\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"\\n⚠️ Dataset needs more images. Total: {total_images}, Recommended: {min_recommended}+\")\n",
        "        print(\"Consider data augmentation or collecting more images\")\n",
        "        return total_images > 100  # Minimum viable dataset\n",
        "\n",
        "def train_complete_model():\n",
        "    \"\"\"Train the complete fraud detection model\"\"\"\n",
        "\n",
        "    print(\"\\n🚀 Starting Model Training Pipeline...\")\n",
        "\n",
        "    try:\n",
        "        # Import training modules\n",
        "        from classification_model import train_uniform_classifier\n",
        "\n",
        "        print(\"Step 1: Training EfficientNet-based classifier...\")\n",
        "        classifier = train_uniform_classifier()\n",
        "\n",
        "        if classifier is not None:\n",
        "            print(\"✅ Model training completed successfully!\")\n",
        "            print(\"Model saved to: models/uniform_classifier.h5\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"❌ Model training failed!\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def run_demo_evaluation():\n",
        "    \"\"\"Run demonstration and evaluation\"\"\"\n",
        "\n",
        "    print(\"\\n🧪 Running Model Evaluation...\")\n",
        "\n",
        "    try:\n",
        "        from testing_evaluation import run_comprehensive_evaluation\n",
        "        run_comprehensive_evaluation()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during evaluation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "def create_demo_video_script():\n",
        "    \"\"\"Create script for recording demo video\"\"\"\n",
        "\n",
        "    demo_script = '''\n",
        "# Demo Video Recording Script\n",
        "# Use this as a guide for creating your demo video\n",
        "\n",
        "\"\"\"\n",
        "DEMO VIDEO SCRIPT - Uniform Fraud Detection System\n",
        "\n",
        "1. INTRODUCTION (30 seconds)\n",
        "   - \"This is a machine learning system to detect fraud calls where criminals impersonate law enforcement\"\n",
        "   - Show project structure and files\n",
        "\n",
        "2. DATA ORGANIZATION (60 seconds)\n",
        "   - Show organized_dataset folder structure\n",
        "   - Explain uniform vs non_uniform categories\n",
        "   - Display sample images from each category\n",
        "\n",
        "3. MODEL TRAINING (90 seconds)\n",
        "   - Run: python main.py --train\n",
        "   - Show training progress and metrics\n",
        "   - Explain EfficientNet-Lite4 architecture\n",
        "\n",
        "4. SEGMENTATION DEMO (60 seconds)\n",
        "   - Show person segmentation using MediaPipe\n",
        "   - Demonstrate region extraction (head, torso)\n",
        "   - Visualize segmentation results\n",
        "\n",
        "5. CLASSIFICATION DEMO (90 seconds)\n",
        "   - Test on sample images\n",
        "   - Show confidence scores and predictions\n",
        "   - Demonstrate both genuine and fraud cases\n",
        "\n",
        "6. COMPLETE PIPELINE (120 seconds)\n",
        "   - Run: python main.py --test <image_path>\n",
        "   - Run batch processing: python main.py --batch <folder_path>\n",
        "   - Show batch results and evaluation report\n",
        "   - Discuss system performance and potential improvements\n",
        "\n",
        "7. CONCLUSION (30 seconds)\n",
        "   - Summarize key features and benefits\n",
        "   - Briefly mention future work or next steps\n",
        "   - Thank viewers and provide contact info (optional)\n",
        "\"\"\"\n",
        "''' # Added the closing triple quotes here\n",
        "\n",
        "    with open('demo_script.txt', 'w') as f:\n",
        "        f.write(demo_script)\n",
        "\n",
        "    print(\"Created 'demo_script.txt' for demo video recording\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Complete Uniform Fraud Detection Pipeline Setup Ready!\")\n",
        "    print(\"\\nAvailable functions:\")\n",
        "    print(\"- setup_project_structure(): Create project directory structure\")\n",
        "    print(\"- organize_existing_data(): Help organize existing data\")\n",
        "    print(\"- check_data_ready(): Check data organization status\")\n",
        "    print(\"- train_complete_model(): Train the model\")\n",
        "    print(\"- run_demo_evaluation(): Run demo and evaluation\")\n",
        "    print(\"- create_demo_video_script(): Create script for demo video\")\n",
        "\n",
        "    # Uncomment to run initial setup\n",
        "    # setup_project_structure()\n",
        "    # organize_existing_data()\n",
        "\n",
        "    # Uncomment to check data status\n",
        "    # check_data_ready()\n",
        "\n",
        "    # Uncomment to train model\n",
        "    # train_complete_model()\n",
        "\n",
        "    # Uncomment to run evaluation\n",
        "    # run_demo_evaluation()\n",
        "\n",
        "    # Uncomment to create demo script\n",
        "    # create_demo_video_script()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_pB3CxBpx9x",
        "outputId": "115f6b3d-cb24-4815-d8d1-56dc2d970506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete Uniform Fraud Detection Pipeline Setup Ready!\n",
            "\n",
            "Available functions:\n",
            "- setup_project_structure(): Create project directory structure\n",
            "- organize_existing_data(): Help organize existing data\n",
            "- check_data_ready(): Check data organization status\n",
            "- train_complete_model(): Train the model\n",
            "- run_demo_evaluation(): Run demo and evaluation\n",
            "- create_demo_video_script(): Create script for demo video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGS_sbpMix3U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}